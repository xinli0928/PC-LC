{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from TinyImageNet import TinyImageNet\n",
    "from hard_margin_loss import MarginLoss\n",
    "from margin_loss_soft_logit import MarginLoss as LogitMargin\n",
    "#32 by 32 image size\n",
    "#from models.vgg import VGG\n",
    "\n",
    "#64 by 64 image size\n",
    "from models.vgg_tiny import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = transforms.RandomApply([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(64)], p=.8)\n",
    "\n",
    "training_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "    augmentation,\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root =\"tiny-imagenet-200\"\n",
    "in_memory = False\n",
    "training_set = TinyImageNet(root, 'train', transform=training_transform, in_memory=in_memory)\n",
    "valid_set = TinyImageNet(root, 'val', transform=valid_transform, in_memory=in_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = VGG('VGG13').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100], gamma=0.2)\n",
    "max_epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(training_set, batch_size=256, shuffle=True, num_workers=8,pin_memory=True)\n",
    "validloader = DataLoader(valid_set, batch_size=64, num_workers=8,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax training\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "assert torch.cuda.is_available()\n",
    "try:\n",
    "    for epoch in range(max_epochs):\n",
    "        start = time.time()\n",
    "        lr_scheduler.step()\n",
    "        epoch_loss = 0.0\n",
    "        model.train()\n",
    "        for idx, (data, target) in enumerate(trainloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output,_ = model(data)\n",
    "\n",
    "            batch_loss = criterion(output, target)\n",
    "            \n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += batch_loss.item()\n",
    "        \n",
    "            if idx % 100 == 0:\n",
    "                print('{:.1f}% of epoch'.format(idx / float(len(trainloader)) * 100), end='\\r')\n",
    "            \n",
    "            \n",
    "        # evaluate on validation set\n",
    "        num_hits = 0\n",
    "        num_instances = len(valid_set)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for idx, (data, target) in enumerate(validloader):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output,_ = model(data)\n",
    "                _, pred = torch.max(output, 1) \n",
    "\n",
    "                num_hits += (pred == target).sum().item()\n",
    "\n",
    "        valid_acc = num_hits / num_instances * 100\n",
    "        print(f' Validation acc: {valid_acc}%')\n",
    "            \n",
    "        epoch_loss /= float(len(trainloader))\n",
    "        \n",
    "        # save model\n",
    "        torch.save(model.state_dict(), 'vgg13_model_CE.pth')\n",
    "        \n",
    "\n",
    "    \n",
    "finally:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PC Loss training\n",
    "model.load_state_dict(torch.load('vgg13_model_CE.pth'))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100], gamma=0.2)\n",
    "logit_margin = LogitMargin()\n",
    "c_margin = MarginLoss(margin=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "assert torch.cuda.is_available()\n",
    "try:\n",
    "    for epoch in range(max_epochs):\n",
    "        start = time.time()\n",
    "        lr_scheduler.step()\n",
    "        epoch_loss = 0.0\n",
    "        model.train()\n",
    "        for idx, (data, target) in enumerate(trainloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output,_ = model(data)\n",
    "\n",
    "            m_loss = c_margin(output, target)\n",
    "            logit_m_loss = logit_margin(output, target)\n",
    "            batch_loss = m_loss + 0.05 * logit_m_loss\n",
    "            \n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += batch_loss.item()\n",
    "        \n",
    "            if idx % 100 == 0:\n",
    "                print('{:.1f}% of epoch'.format(idx / float(len(trainloader)) * 100), end='\\r')\n",
    "            \n",
    "            \n",
    "        # evaluate on validation set\n",
    "        num_hits = 0\n",
    "        num_instances = len(valid_set)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for idx, (data, target) in enumerate(validloader):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output,_ = model(data)\n",
    "                _, pred = torch.max(output, 1) \n",
    "\n",
    "                num_hits += (pred == target).sum().item()\n",
    "\n",
    "        valid_acc = num_hits / num_instances * 100\n",
    "        print(f' Validation acc: {valid_acc}%')\n",
    "            \n",
    "        epoch_loss /= float(len(trainloader))\n",
    "       \n",
    "        # save model\n",
    "        torch.save(model.state_dict(), 'vgg13_model_PC_loss_995.pth')\n",
    "        \n",
    "finally:\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}